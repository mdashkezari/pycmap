{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TN268', 'KOK1604', 'KOK1803', 'TN271', 'KM1427', 'KM1508', 'KM1513', 'KOK1607', 'KOK1805', 'KOK1806', 'KOK1515', 'TN264-265', 'KM1802', 'TN270', 'TN243', 'KM1603', 'KM1823', 'KM1906', 'CN13ID', 'KOK1801', 'TN257', 'KM1602', 'TN250', 'CN11ID', 'TN248', 'KM1512', 'KM1805', 'KM1821', 'KM1903', 'KM1909', 'KM1518', 'TN260', 'KOK1804', 'KOK1608', 'CN12ID', 'KOK1609', 'FK180310-2', 'KOK1512', 'TN252', 'KM1901', 'KM1709', 'KM1708', 'KM1510', 'TN291', 'KM1601', 'FK180310-1', 'TN280', 'KM1717']\n"
     ]
    }
   ],
   "source": [
    "import pycmap\n",
    "api = pycmap.API(token='', vizEngine='plotly')\n",
    "pycmap.__version__\n",
    "\n",
    "\n",
    "# croco is missing at gradients1&2?\n",
    "# no seaflow data for tokyo cruises? tokyo_4 specially\n",
    "# RR1814/15 no sf data?\n",
    "# fair to replace null values with 0?\n",
    "\n",
    "# from pycmap.viz import plot_cruise_track\n",
    "# plot_cruise_track('KM1502')\n",
    "\n",
    "# api.cruises()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def all_cruises():\n",
    "    cruises = list(api.cruises().Name)[:-21]   # remove AMT cruises\n",
    "    cruises.remove('Tokyo_1')\n",
    "    cruises.remove('Tokyo_2')\n",
    "    cruises.remove('Tokyo_3')\n",
    "    cruises.remove('Tokyo_4')\n",
    "    return cruises\n",
    "\n",
    "\n",
    "def open_ocean_cruises():\n",
    "    return ['RR1814', 'RR1815', 'MGL1704', 'KOK1606', 'KM1713', 'KM1712', 'KM1502', 'KM1314', 'KN210-04', 'TN292']        \n",
    "\n",
    "def not_open_ocean_cruises():\n",
    "    all = all_cruises()\n",
    "    open = open_ocean_cruises()\n",
    "    return list(set(all) - set(open))        \n",
    "\n",
    "not_open_ocean_cruises()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Param = namedtuple('Param', ['table', 'variable', 'temporalTolerance', 'latTolerance', 'lonTolerance', 'depthTolerance'])\n",
    "\n",
    "params = []\n",
    "params.append(Param('tblSeaFlow', 'prochloro_abundance', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'prochloro_diameter', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'prochloro_carbon_content', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'prochloro_biomass', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'synecho_abundance', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'synecho_diameter', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'synecho_carbon_content', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'synecho_biomass', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'picoeuk_abundance', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'picoeuk_diameter', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'picoeuk_carbon_content', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'picoeuk_biomass', 0, 0.1, 0.1, 5))\n",
    "# params.append(Param('tblSeaFlow', 'croco_abundance', 0, 0.1, 0.1, 5))\n",
    "# params.append(Param('tblSeaFlow', 'croco_diameter', 0, 0.1, 0.1, 5))\n",
    "# params.append(Param('tblSeaFlow', 'croco_carbon_content', 0, 0.1, 0.1, 5))\n",
    "# params.append(Param('tblSeaFlow', 'croco_biomass', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'total_biomass', 0, 0.1, 0.1, 5))\n",
    "params.append(Param('tblSeaFlow', 'par', 0, 0.1, 0.1, 5))\n",
    "\n",
    "\n",
    "######## satellite\n",
    "params.append(Param('tblSST_AVHRR_OI_NRT', 'sst', 1, 0.25, 0.25, 5))\n",
    "params.append(Param('tblSSS_NRT', 'sss', 1, 0.25, 0.25, 5))\n",
    "params.append(Param('tblCHL_REP', 'chl', 4, 0.25, 0.25, 5))\n",
    "params.append(Param('tblModis_AOD_REP', 'AOD', 15, 1, 1, 5))\n",
    "params.append(Param('tblAltimetry_REP', 'sla', 1, 0.25, 0.25, 5))\n",
    "params.append(Param('tblAltimetry_REP', 'adt', 1, 0.25, 0.25, 5))\n",
    "params.append(Param('tblAltimetry_REP', 'ugos', 1, 0.25, 0.25, 5))\n",
    "params.append(Param('tblAltimetry_REP', 'vgos', 1, 0.25, 0.25, 5))\n",
    "# params.append(Param('tblLCS_REP', 'ftle_bw_sla', 1, 0.125, 0.125, 5))\n",
    "# params.append(Param('tblLCS_REP', 'ftle_fw_sla', 1, 0.125, 0.125, 5))\n",
    "# params.append(Param('tblLCS_REP', 'disp_bw_sla', 1, 0.125, 0.125, 5))\n",
    "\n",
    "\n",
    "\n",
    "######## model\n",
    "params.append(Param('tblPisces_NRT', 'Fe', 4, 0.5, 0.5, 5))\n",
    "params.append(Param('tblPisces_NRT', 'NO3', 4, 0.5, 0.5, 5))\n",
    "params.append(Param('tblPisces_NRT', 'O2', 4, 0.5, 0.5, 5))\n",
    "params.append(Param('tblPisces_NRT', 'PO4', 4, 0.5, 0.5, 5))\n",
    "params.append(Param('tblPisces_NRT', 'Si', 4, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'NH4_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'NO2_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'SiO2_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'DOC_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'DON_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'DOP_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'DOFe_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'PIC_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'ALK_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "params.append(Param('tblDarwin_Nutrient_Climatology', 'FeT_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "\n",
    "####### WOA\n",
    "params.append(Param('tblWOA_Climatology', 'density_WOA_clim', 0, .75, .75, 5))\n",
    "params.append(Param('tblWOA_Climatology', 'nitrate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "params.append(Param('tblWOA_Climatology', 'phosphate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "params.append(Param('tblWOA_Climatology', 'silicate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "params.append(Param('tblWOA_Climatology', 'oxygen_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = [], [], [], [], [], []\n",
    "for i in range(len(params)):\n",
    "    tables.append(params[i].table)\n",
    "    variables.append(params[i].variable)\n",
    "    temporalTolerance.append(params[i].temporalTolerance)\n",
    "    latTolerance.append(params[i].latTolerance)\n",
    "    lonTolerance.append(params[i].lonTolerance)\n",
    "    depthTolerance.append(params[i].depthTolerance)\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************\n",
      "Preparing KOK1512 cruise...\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4eb7f2fb9e4edb985bf913dc192274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='overall', max=40, style=ProgressStyle(description_width='initâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: prochloro_abundance matched.\n",
      "\n",
      "2: prochloro_diameter matched.\n",
      "\n",
      "3: prochloro_carbon_content matched.\n",
      "\n",
      "4: prochloro_biomass matched.\n",
      "\n",
      "5: synecho_abundance matched.\n",
      "\n",
      "6: synecho_diameter matched.\n",
      "\n",
      "7: synecho_carbon_content matched.\n",
      "\n",
      "8: synecho_biomass matched.\n",
      "\n",
      "9: picoeuk_abundance matched.\n",
      "\n",
      "10: picoeuk_diameter matched.\n",
      "\n",
      "11: picoeuk_carbon_content matched.\n",
      "\n",
      "12: picoeuk_biomass matched.\n",
      "\n",
      "13: total_biomass matched.\n",
      "\n",
      "14: par matched.\n",
      "\n",
      "15: sst matched.\n",
      "\n",
      "16: sss matched.\n",
      "\n",
      "17: chl matched.\n",
      "\n",
      "18: AOD matched.\n",
      "\n",
      "19: sla matched.\n",
      "\n",
      "20: adt matched.\n",
      "\n",
      "21: ugos matched.\n",
      "\n",
      "22: vgos matched.\n",
      "\n",
      "23: Fe matched.\n",
      "\n",
      "24: NO3 matched.\n",
      "\n",
      "25: O2 matched.\n",
      "\n",
      "26: PO4 matched.\n",
      "\n",
      "27: Si matched.\n",
      "\n",
      "28: NH4_darwin_clim matched.\n",
      "\n",
      "29: NO2_darwin_clim matched.\n",
      "\n",
      "30: SiO2_darwin_clim matched.\n",
      "\n",
      "31: DOC_darwin_clim matched.\n",
      "\n",
      "32: DON_darwin_clim matched.\n",
      "\n",
      "33: DOP_darwin_clim matched.\n",
      "\n",
      "34: DOFe_darwin_clim matched.\n",
      "\n",
      "35: PIC_darwin_clim matched.\n",
      "\n",
      "36: ALK_darwin_clim matched.\n",
      "\n",
      "37: density_WOA_clim matched.\n",
      "\n",
      "38: nitrate_WOA_clim matched.\n",
      "\n",
      "39: phosphate_WOA_clim matched.\n",
      "\n",
      "40: silicate_WOA_clim matched.\n",
      "\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    " \n",
    "# cruises = list(api.cruises().Name)[:-21]   # remove AMT cruises\n",
    "# cruises.remove('Tokyo_1')\n",
    "# cruises.remove('Tokyo_2')\n",
    "# cruises.remove('Tokyo_3')\n",
    "# cruises.remove('Tokyo_4')\n",
    "\n",
    "# cruises = ['Gradients_1', 'Gradients_2', 'KM1712', 'KM1713']\n",
    "cruises = ['RR1814', 'RR1815', 'MGL1704', 'KOK1606', 'KM1713', 'KM1712', 'KM1502', 'KM1314', 'KN210-04', 'TN292']\n",
    "df = pd.DataFrame({})\n",
    "for cruise in cruises:\n",
    "    print('')\n",
    "    print('********************************')\n",
    "    print('Preparing %s cruise...' % cruise)\n",
    "    print('********************************')\n",
    "    data = api.along_track(\n",
    "                          cruise=cruise,     \n",
    "                          tables=tables,\n",
    "                          variables=variables,\n",
    "                          temporalTolerance=temporalTolerance, \n",
    "                          latTolerance=latTolerance, \n",
    "                          lonTolerance=lonTolerance, \n",
    "                          depthTolerance=depthTolerance,\n",
    "                          depth1=0,\n",
    "                          depth2=5\n",
    "                          )\n",
    "\n",
    "    if len(df) < 1:\n",
    "        df = data\n",
    "    else:\n",
    "        df = pd.concat([df, data], ignore_index=True)\n",
    "    \n",
    "    data.to_csv('export/%s.csv' % cruise, index=False)\n",
    "\n",
    "# df.to_csv('export/transects.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile all cruises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_cruises():\n",
    "    cruises = list(api.cruises().Nickname)[:-21]   # remove AMT cruises\n",
    "    cruises.remove('Tokyo_1')\n",
    "    cruises.remove('Tokyo_2')\n",
    "    cruises.remove('Tokyo_3')\n",
    "    cruises.remove('Tokyo_4')\n",
    "    cruises.remove('KOK1512')\n",
    "    return cruises\n",
    "\n",
    "\n",
    "def compile():\n",
    "    df = pd.DataFrame({})\n",
    "    cruises = get_cruises()\n",
    "    for index, cruise in enumerate(cruises):\n",
    "        print('%d: %s' % (index, cruise))\n",
    "        data = pd.read_csv('export/%s.csv' % cruise)\n",
    "        if len(df) < 1:\n",
    "            df = data\n",
    "        else:\n",
    "            df = pd.concat([df, data], ignore_index=True)    \n",
    "        data.to_csv('export/%s.csv' % cruise, index=False)\n",
    "    df.to_csv('export/sfCompile.csv', index=False)      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from pycmap.clean import Clean\n",
    "\n",
    "def data_transform(df):\n",
    "    def power(col):\n",
    "        shift = df[col].min()\n",
    "        if shift < 0:\n",
    "            shift = -shift\n",
    "        else:\n",
    "            shift = 0 \n",
    "            \n",
    "        df['%s_2' % col] = df[col] ** 2 \n",
    "        df['%s_0.5' % col] = df[col] ** 0.5 \n",
    "#         df['1_%s' % col] = df[col] ** -1 \n",
    "#         df['log_%s' % col] = stats.boxcox(df[col]+shift+1, lmbda=0) \n",
    "        df['boxcox_%s' % col], _ = stats.boxcox(df[col]+shift+1)\n",
    "        \n",
    "    df = Clean(df).remove_nan_time_std()\n",
    "\n",
    "    df.drop('year', axis=1, inplace=True) \n",
    "    df.drop('month', axis=1, inplace=True)\n",
    "\n",
    "    power('sst') \n",
    "    power('sss') \n",
    "    power('NO3') \n",
    "    power('Fe') \n",
    "\n",
    "    df['vel'] = ( (df.ugos ** 2) + (df.vgos ** 2) ) ** 0.5    \n",
    "    df['Fe_div_NO3'] = df.Fe/df.NO3\n",
    "\n",
    "    \n",
    "\n",
    "    # 1/lat?\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmap.annotatedHeatmap import AnnotatedHeatmap\n",
    "\n",
    "def plot_corr_matrix(df, cruise):\n",
    "    corr = df.corr(method='spearman')\n",
    "    go = AnnotatedHeatmap().graph_obj()        \n",
    "    go.x = list(corr.columns)\n",
    "    go.y = list(corr.columns)\n",
    "    go.z = corr.values\n",
    "    go.cmap = 'coolwarm' \n",
    "    go.vmin = -1\n",
    "    go.vmax = 1\n",
    "    go.variable = 'SF'\n",
    "    go.xlabel = ''\n",
    "    go.ylabel = ''\n",
    "    go.title = cruise\n",
    "    go.width = 1500\n",
    "    go.height = 1500\n",
    "    go.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_save(df):\n",
    "    corr = df.corr(method='spearman')\n",
    "    corr.reset_index(inplace=True)\n",
    "    corr.to_csv('export/sfCompile_corr.csv', index=False)\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycmap.trend import Trend\n",
    "\n",
    "\n",
    "def plot_spearman(col, path='export/sfCompile_corr.csv'):\n",
    "    corr = pd.read_csv(path)\n",
    "    corr = corr.sort_values(by=col, ascending=False)\n",
    "    go = Trend(pd.DataFrame({}), col).graph_obj()\n",
    "    go.x = list(corr['index'])\n",
    "    go.y = list(corr[col])\n",
    "    go.title = 'spearman -- ' + col\n",
    "    go.timeSeries = False\n",
    "    go.ylabel = 'Spearman Coeff. for ' + col\n",
    "    go.width = 1100\n",
    "    go.height = 600\n",
    "    go.render()\n",
    "        \n",
    "        \n",
    "# plot_spearman('prochloro_abundance')  ## Fe/NO3, O2/sst       \n",
    "# plot_spearman('prochloro_diameter')        \n",
    "# plot_spearman('prochloro_biomass')        \n",
    "\n",
    "# plot_spearman('synecho_abundance')  ## Fe/NO3, SiO2, ALK\n",
    "# plot_spearman('synecho_diameter')  \n",
    "# plot_spearman('synecho_biomass')  ## Fe/NO3, vel!\n",
    "\n",
    "# plot_spearman('picoeuk_abundance')\n",
    "# plot_spearman('picoeuk_diameter')\n",
    "# plot_spearman('picoeuk_biomass')  ## Fe/NO3, vel!\n",
    "\n",
    "plot_spearman('total_biomass')  # ALK, SIO2, density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('export/sfCompile.csv')\n",
    "df = data_transform(df)\n",
    "spearman_save(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycmap.supervised import RandomForest\n",
    "\n",
    "model = RandomForest(df, 'prochloro_abundance', max_features='sqrt')\n",
    "model.learn()\n",
    "model.plot_feature_importance()\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmap.supervised import RandomForest\n",
    "\n",
    "df_syn = \n",
    "model = RandomForest(df, 'synecho_abundance', max_features='auto', standard=True)\n",
    "model.learn()\n",
    "model.plot_feature_importance()\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmap.supervised import RandomForest\n",
    "\n",
    "model = RandomForest(df, 'synecho_diameter', max_features='sqrt', standard=True)\n",
    "model.learn()\n",
    "model.plot_feature_importance()\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycmap.supervised import RandomForest\n",
    "\n",
    "model = RandomForest(df, 'picoeuk_abundance')\n",
    "model.learn()\n",
    "model.plot_feature_importance()\n",
    "model.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycmap.annotatedHeatmap import AnnotatedHeatmap\n",
    "from pycmap.clean import Clean\n",
    "import pandas as pd\n",
    "\n",
    "def plot_corr_matrix(df, cruise):\n",
    "    corr = df.corr(method='spearman')\n",
    "    go = AnnotatedHeatmap().graph_obj()        \n",
    "    go.x = list(corr.columns)\n",
    "    go.y = list(corr.columns)\n",
    "    go.z = corr.values\n",
    "    go.cmap = 'coolwarm' \n",
    "    go.vmin = -1\n",
    "    go.vmax = 1\n",
    "    go.variable = 'SeaFlow'\n",
    "    go.xlabel = ''\n",
    "    go.ylabel = ''\n",
    "    go.title = cruise\n",
    "    go.width = 1500\n",
    "    go.height = 1500\n",
    "    go.render()\n",
    "    \n",
    "    \n",
    "cruises = ['Gradients_1', 'Gradients_2', 'KM1712', 'KM1713', 'meso_scope', 'diel']\n",
    "for cruise in cruises:\n",
    "    df = pd.read_csv('export/%s.csv' % cruise)\n",
    "    df = Clean(df).remove_nan_time_std()\n",
    "    df.drop('year', axis=1, inplace=True) \n",
    "    df.drop('month', axis=1, inplace=True) \n",
    "    plot_corr_matrix(df, cruise)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
